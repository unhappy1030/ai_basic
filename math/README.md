### 확률 분포(probability distribution)

### KL divergence

Kullback-Leibler(KL) divergence는 확률 분포 간의 차이를 측정하는 통계적 방법<br/>
![KL_divergence](./image/KL_divergence.png)

p에 대한 q의 근사 정도를 측정 한다, 그러므로 q에서 발생한 정보 손실의 정도를 층정하기 위해서 KL-divergence를 사용한다.
